# Software Development Lifecycle (SDLC) - Complete Guide

> A comprehensive guide for software engineers to understand and master the SDLC process.

---

## Table of Contents

1. [Overview](#overview)
2. [Phase 1: Requirements Gathering & Analysis](#phase-1-requirements-gathering--analysis)
3. [Phase 2: System Design & Architecture](#phase-2-system-design--architecture)
4. [Technical Modeling (UML Diagrams)](#technical-modeling-uml-diagrams)
5. [Phase 3: Implementation (Coding)](#phase-3-implementation-coding)
6. [Phase 4: Testing](#phase-4-testing)
7. [Phase 5: Deployment](#phase-5-deployment)
8. [Phase 6: Maintenance & Operations](#phase-6-maintenance--operations)
9. [Phase 7: Iteration & Evolution](#phase-7-iteration--evolution)
10. [SDLC Models](#sdlc-models)
11. [Key Takeaways](#key-takeaways)
12. [Resources](#resources)

---

## Overview

The **Software Development Lifecycle (SDLC)** is simply a **step-by-step plan** for building software. Just like you need a recipe to bake a cake or blueprints to build a house, you need SDLC to build software correctly.

It ensures you don't just start coding randomly (which leads to mess) but follow a clear path from "I have an idea" to "The users are happy."

### ğŸ  The "House Building" Analogy
To make it easier, think of building software like building a house:

1.  **Requirements**: "We need a 3-bedroom house with a pool." (Deciding *what* to build)
2.  **Design**: The architect draws the blueprints. (Deciding *how* to build it)
3.  **Implementation**: The construction workers pour concrete and put up walls. (Actual *building*)
4.  **Testing**: The inspector checks if the electricity works and the roof doesn't leak. (*checking* work)
5.  **Deployment**: The family moves in. (Going *live*)
6.  **Maintenance**: Fixing a leaky faucet or painting the walls next year. (*Upkeep*)

---

### Why Use SDLC?

-   **Less Chaos**: Everyone knows what to do next.
-   **Save Money**: Catching a mistake on the blueprint (Design) is cheaper than tearing down a wall (Implementation).
-   **Better Quality**: You don't forget important things like "testing" or "security."

### SDLC Visual Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  THE SOFTWARE LIFECYCLE LOOP                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚      1. REQUIREMENTS  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶  2. DESIGN                     â”‚
â”‚             â–²                          â”‚                         â”‚
â”‚             â”‚                          â”‚                         â”‚
â”‚      7. ITERATION                      â–¼                         â”‚
â”‚             â”‚                  3. IMPLEMENTATION                 â”‚
â”‚             â”‚                          â”‚                         â”‚
â”‚      6. MAINTENANCE                    â–¼                         â”‚
â”‚             â”‚                     4. TESTING                     â”‚
â”‚             â”‚                          â”‚                         â”‚
â”‚             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â—€  5. DEPLOYMENT                          â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Phase 1: Requirements Gathering & Analysis

### ğŸ“‹ What Happens
In this phase, we figure out **what** we are building. We talk to the people who want the software (stakeholders) and the people who will use it (users) to make a list of features.

### How Experienced Engineers Approach It

| Approach | Description |
|----------|-------------|
| **Be Active** | Don't just listen in meetingsâ€”ask questions and suggest ideas. |
| **Ask "Why?"** | If a user asks for a feature, ask *why* they need it to understand the real problem. |
| **Write it Down** | Don't rely on memory. Write down what everyone agrees on. |
| **Think of "What If?"** | What if the internet goes down? What if the user types a emoji in a number field? |

### Best Practices

| Practice | Description |
|----------|-------------|
| **Use Templates** | Don't start from scratch; use a standard form for requirements. |
| **Prioritize** | Decide what is "Must Have" vs. "Nice to Have" (MoSCoW method). |
| **Draw Sketches** | Draw simple pictures (prototypes) to show what you mean. |
| **Track Changes** | Keep a history of who asked for what change and when. |

### User Story Template
A "User Story" is a simple sentence that describes a feature from the user's point of view.

```
As a [type of user],
I want [an action or feature],
So that [benefit/value].
```

### Example User Story

```
As a mobile banking user,
I want to transfer money using my fingerprint,
So that I can complete transactions quickly and securely.

Acceptance Criteria:
- Given I'm on the transfer screen, when I place my finger on the sensor, then the 
transfer is authenticated
- Given the fingerprint doesn't match, when I try to transfer, then I see an error and can retry up to 3 times
- Given I've exceeded retry attempts, when I try again, then I'm locked out for 30 minutes
```

### Real-World Example: Spotify's "Discover Weekly"

- **Requirement**: Users want personalized music recommendations
- **Analysis**: Engineers identified that users wanted *fresh* recommendations, not just similar songs they already liked
- **Key Insight**: Users wanted discovery, not just similarity
- **Outcome**: Weekly playlist that feels personal, updated every Monday
- **Success Metric**: 40 million users in first year

### Common Pitfalls & Issues

| Pitfall | Real Issue Faced | Solution |
|---------|------------------|----------|
| **Scope creep** | Netflix initially tried to add too many social features, delaying core improvements | Strict change control process with impact analysis |
| **Vague requirements** | "Make it fast" without defining metrics led to endless optimization | Define measurable criteria (e.g., <200ms response time) |
| **Missing stakeholders** | Instagram didn't initially consult advertisers, causing later friction | Comprehensive stakeholder mapping at project start |
| **Gold plating** | Engineers adding unrequested "cool" features | Stick to documented requirements only |
| **Analysis paralysis** | Over-analyzing requirements delays development | Time-box analysis phase, use prototypes to validate |
| **Assuming not asking** | Developers assumed user needs without validation | Conduct user interviews and surveys |

### Deliverables Checklist

- [ ] Software Requirements Specification (SRS)
- [ ] User stories with acceptance criteria
- [ ] Use case diagrams
- [ ] Requirements traceability matrix
- [ ] Stakeholder sign-off documentation
- [ ] Project scope document
- [ ] Risk assessment

---

## Phase 2: System Design & Architecture

### ğŸ¨ What Happens
We turn the requirements into a **technical blueprint**. We decide how to structure the code, which database to use, and how different parts of the system will talk to each other.

### How Experienced Engineers Approach It

| Approach | Description |
|----------|-------------|
| **Know the Limits** | Consider budget, deadline, and team size before designing. |
| **Plan for Failure** | Assume things will break (e.g., database goes offline) and plan how to handle it. |
| **Keep it Simple (KISS)** | Don't over-complicate things. Simple is better. |
| **Write Down Decisions** | When you choose a technology (e.g., "We will use Python"), write down *why*. |

### Best Practices

```
âœ… Explore multiple options before picking one
âœ… Use standard ways of building (Design Patterns)
âœ… Plan for growth (Scalability)
âœ… Think about security from day one
âœ… Ask other engineers to review your design
```

### Architecture Decision Record (ADR)
An ADR is just a short document that explains a big technical choice.

```markdown
# Decision: Use PostgreSQL Database

## Why?
We need a reliable database that handles complex queries.

## What we decided
We will use PostgreSQL version 15.

## Other options
We looked at MongoDB but it wasn't good for our data structure.
```

### Common Architecture Patterns

#### 1. Monolithic Architecture (The "All-in-One")
Think of this like a **Studio Apartment**. Everything (kitchen, bed, living room) is in one big room.
- **Pros**: Easy to start, simple to deploy.
- **Cons**: If one part catches fire, the whole house burns down. Hard to scale up.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            APPLICATION              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”         â”‚
â”‚  â”‚ UI  â”‚  â”‚Logicâ”‚  â”‚ Dataâ”‚         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”˜         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚Database â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```
**Best For**: Startups, small teams, simple apps.

#### 2. Microservices Architecture (The "Mansion")
Think of this like a **Large House with specific rooms**. The kitchen is separate from the bedroom.
- **Pros**: If the kitchen sink leaks, you can still sleep in the bedroom. Teams can work on different rooms at the same time.
- **Cons**: Complex to build and connect everything.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Service â”‚   â”‚ Service â”‚   â”‚ Service â”‚
â”‚    A    â”‚   â”‚    B    â”‚   â”‚    C    â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
     â”‚             â”‚             â”‚
     â–¼             â–¼             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   DB A  â”‚   â”‚   DB B  â”‚   â”‚   DB C  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```
**Best For**: Big companies (Netflix, Uber), large teams.

#### 3. Event-Driven Architecture
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Producer â”‚â”€â”€â”€â”€â–¶â”‚ Event Queue  â”‚â”€â”€â”€â”€â–¶â”‚ Consumer â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                 â”‚ Consumer â”‚
                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```
**When to use**: Asynchronous processing, decoupled systems, high throughput

### Real-World Example: Twitter's Architecture Evolution

| Phase | Architecture | Problem | Solution |
|-------|-------------|---------|----------|
| **2006-2009** | Monolithic Ruby on Rails | "Fail Whale" during high traffic | Couldn't scale |
| **2010-2012** | Service-oriented | Complex dependencies | Introduced microservices |
| **2012-Present** | Microservices | Performance issues | Separate services for timeline, tweets, users |

**Current Scale**: Handles 500 million tweets/day

### Common Pitfalls & Issues

| Pitfall | Real Issue Faced | Solution |
|---------|------------------|----------|
| **Over-engineering** | Premature optimization at Friendster led to delays and eventual failure | Build for current scale + 10x, not 1000x |
| **Ignoring NFRs** | Healthcare.gov crashed on launch (2013) due to untested load | Load test with realistic traffic patterns |
| **Tight coupling** | eBay's early monolith was extremely hard to modify | Design loosely coupled services with clear interfaces |
| **No disaster recovery** | GitLab lost 6 hours of production data (2017) | Design backup and recovery from day 1 |
| **Distributed monolith** | Microservices without proper boundaries | Ensure services are truly independent |
| **Ignoring team structure** | Architecture didn't match team organization | Apply Conway's Law consciously |

### Deliverables Checklist

- [ ] High-level architecture diagram
- [ ] Component/service specifications
- [ ] Database schema design
- [ ] API contracts/specifications
- [ ] Security architecture
- [ ] Infrastructure requirements
- [ ] Architecture Decision Records (ADRs)
- [ ] Non-functional requirements mapping

---

## Technical Modeling (UML Diagrams)

**Unified Modeling Language (UML)** is a standardized visual language for modeling software systems. It helps developers, architects, and stakeholders understand system structure and behavior.

### 1. Structural Diagrams

**Purpose**: Shows static structure (Class, Object, Component, Deployment).

#### Class Diagram Example (E-Commerce)
Shows classes, attributes, methods, and relationships.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      Customer       â”‚ 1   * â”‚       Order         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤â”€â”€â”€â”€â”€â”€â”€â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ - customerId: int   â”‚       â”‚ - orderId: int      â”‚
â”‚ + placeOrder()      â”‚       â”‚ + calculateTotal()  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Deployment Diagram Example (Web App)
Shows physical deployment of artifacts on nodes.

```
[ Client Browser ] â”€â”€HTTPSâ”€â”€> [ Load Balancer ]
                                     â”‚
                             â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”
                        [ Server 1 ]   [ Server 2 ]
                             â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                                     â–¼
                                [ Database ]
```

### 2. Behavioral Diagrams

**Purpose**: Shows dynamic behavior (Use Case, Activity, Sequence).

#### Use Case Diagram Example (ATM)
Shows interactions between actors (Users) and the system.

```
     User â”€â”€â”€> ( Withdraw Cash )
      â”‚
      â””â”€â”€â”€> ( Check Balance ) 
```

#### Sequence Diagram Example (Checkout)
Shows object interactions over time.

```
Customer      App          API          DB
   â”‚ Click     â”‚            â”‚            â”‚
   â”‚ Checkout  â”‚            â”‚            â”‚
   â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚  Create    â”‚            â”‚
   â”‚           â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚   Save     â”‚
   â”‚           â”‚            â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚
   â”‚           â”‚            â”‚  Success   â”‚
   â”‚           â”‚<â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚<â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
```

---

## Phase 3: Implementation (Coding)

### ğŸ’» What Happens
This is the "Construction" phase. Developers write the code. This is usually the longest part of the project.

### How Experienced Engineers Approach It

| Approach | Description |
|----------|-------------|
| **Write Readable Code** | Code is read by humans more than computers. Make it easy to understand. |
| **Save Often** | Commit your code (save it to Git) frequently so you don't lose work. |
| **Clean As You Go** | Don't leave a mess. If you see messy code, fix it. |
| **Don't Be a Hero** | If you are stuck, ask for help. Pair programming (working together) is great. |

### Best Practices

#### Code Quality Example
Imagine asking someone to calculate a price.

**âŒ Bad Way (Confusing):**
```python
def c(x):
    return x * 1.08 # What is 1.08? What is c?
```

**âœ… Good Way (Clear):**
```python
TAX_RATE = 1.08

def calculate_total_price(price):
    return price * TAX_RATE
```

#### Git Commit Messages
When you save your work (commit), leave a message that explains **why** you made the change.

**Template:**
```
[Type]: [Short Description]

[More details if needed]
```

**Example:**
`fix: Repair login bug where users couldn't reset password`

    ### Code Review Checklist

    ```markdown
    ## Functionality
    - [ ] Code does what it's supposed to do
    - [ ] Edge cases are handled
    - [ ] Error handling is appropriate

    ## Code Quality
    - [ ] Code is readable and self-documenting
    - [ ] No code duplication (DRY)
    - [ ] Functions are small and focused
    - [ ] Naming is clear and consistent

    ## Testing
    - [ ] Unit tests are included
    - [ ] Tests cover happy path and edge cases
    - [ ] Tests are readable and maintainable

    ## Security
    - [ ] No hardcoded secrets
    - [ ] Input validation is present
    - [ ] No SQL injection vulnerabilities
    - [ ] Authentication/authorization checked

    ## Performance
    - [ ] No obvious performance issues
    - [ ] Database queries are optimized
    - [ ] No N+1 query problems
    ```

    ### Real-World Example: Google's Code Review Culture

    | Metric | Value |
    |--------|-------|
    | Codebase size | 2 billion lines of code |
    | Review requirement | Every change needs at least one reviewer |
    | Average review time | < 24 hours |
    | Special reviews | Code readability reviews for new employees |

    **Result**: Consistent, high-quality codebase across thousands of engineers

    ### Common Pitfalls & Issues

    | Pitfall | Real Issue Faced | Solution |
    |---------|------------------|----------|
    | **Technical debt** | Facebook's PHP codebase became unmaintainable | Regular refactoring sprints, 20% rule |
    | **Not handling errors** | Knight Capital lost $440M in 45 min (2012) due to unhandled edge case | Defensive programming, fail-safe defaults |
    | **Hardcoded configs** | Environment-specific code broke deployments | Use environment variables and config files |
    | **Ignoring performance** | Slack's initial slow startup times frustrated users | Profile and optimize hot paths early |
    | **Copy-paste coding** | Duplicated bugs across codebase | Extract common functionality, DRY principle |
    | **No code reviews** | Bugs shipped to production undetected | Mandatory peer reviews for all changes |

    ### Deliverables Checklist

    - [ ] Source code in version control
    - [ ] Unit tests with adequate coverage
    - [ ] Code documentation (inline and API docs)
    - [ ] Build scripts and configurations
    - [ ] Development environment setup guide
    - [ ] Code review completion

    ---

## Phase 4: Testing

### ğŸ§ª What Happens
We check if the software works like it's supposed to. We try to break it before the users do.

### How Experienced Engineers Approach It

| Approach | Description |
|----------|-------------|
| **Automate It** | Computers are faster at testing than humans. Write code to test your code. |
| **Test Small Parts** | Test individual functions (Unit Tests) first. |
| **Test Real Scenarios** | Test how a real user would check out or log in. |
| **Don't Assume** | Just because it works on your machine doesn't mean it works everywhere. |

### The "Testing Pyramid" (Do lots of small checks!)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 E2E Tests (10%)                 â”‚  â† Like test driving the car (Slow)
â”‚          (Full user journeys)                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚           Integration Tests (20%)               â”‚  â† Checking if engine connects to wheels
â”‚        (API, database, services)                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚              Unit Tests (70%)                   â”‚  â† Checking each screw (Fast)
â”‚         (Individual functions)                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Types of Testing Simplified

| Type | Simple Explanation | Example |
|------|-------------------|---------|
| **Unit Testing** | Testing one tiny piece. | Does `1 + 1 = 2`? |
| **Integration Testing** | Testing two things working together. | Does the login button actually talk to the database? |
| **End-to-End (E2E)** | Testing the whole flow. | Can a user create an account, buy an item, and get an email? |
| **Load Testing** | Stress testing. | What happens if 10,000 people visit at once? |

### Test Example (Python with pytest)

```python
import pytest
from decimal import Decimal
from myapp.pricing import calculate_total_with_tax, TAX_RATE

class TestCalculateTotalWithTax:
    """Tests for the calculate_total_with_tax function."""
    
    def test_basic_calculation(self):
        """Should correctly calculate tax for a simple amount."""
        result = calculate_total_with_tax(Decimal("100.00"))
        assert result == Decimal("108.25")
    
    def test_zero_amount(self):
        """Should handle zero subtotal."""
        result = calculate_total_with_tax(Decimal("0"))
        assert result == Decimal("0")
    
    def test_large_amount(self):
        """Should handle large amounts without overflow."""
        result = calculate_total_with_tax(Decimal("1000000.00"))
        expected = Decimal("1000000.00") * (1 + TAX_RATE)
        assert result == expected
    
    def test_decimal_precision(self):
        """Should maintain decimal precision."""
        result = calculate_total_with_tax(Decimal("99.99"))
        # Verify precision is maintained
        assert result == Decimal("108.2391675")
    
    @pytest.mark.parametrize("subtotal,expected", [
        (Decimal("50.00"), Decimal("54.125")),
        (Decimal("200.00"), Decimal("216.50")),
        (Decimal("0.01"), Decimal("0.01082500")),
    ])
    def test_various_amounts(self, subtotal, expected):
        """Should calculate correctly for various amounts."""
        result = calculate_total_with_tax(subtotal)
        assert result == expected
```

### Real-World Example: Amazon's Testing Strategy

| Metric | Value |
|--------|-------|
| Deployment frequency | Every 11.7 seconds on average |
| Automated test coverage | 99% of bugs caught before production |
| Canary deployments | New code goes to 1% of servers first |
| A/B testing | Every feature tested with real users |

### Common Pitfalls & Issues

| Pitfall | Real Issue Faced | Solution |
|---------|------------------|----------|
| **No tests** | Therac-25 radiation machine killed patients (1980s) due to untested race condition | Mandatory test coverage requirements |
| **Flaky tests** | Tests pass/fail randomly, team ignores them | Fix or delete flaky tests immediately |
| **Testing only happy path** | Ariane 5 rocket exploded (1996) due to untested integer overflow | Test edge cases and error conditions |
| **Testing in isolation** | Works on dev machine, fails in production | Use containers, test in staging environment |
| **Too many E2E tests** | Test suite takes hours to run, developers skip it | Follow test pyramid, more unit tests |
| **Testing implementation** | Tests break on refactoring even when behavior unchanged | Test behavior and outputs, not internals |

### Test Coverage Guidelines

| Type of Code | Recommended Coverage |
|--------------|---------------------|
| Critical business logic | 90-100% |
| API endpoints | 80-90% |
| Utility functions | 70-80% |
| UI components | 60-70% |
| Generated code | Can be lower |

### Deliverables Checklist

- [ ] Unit tests with coverage report
- [ ] Integration test suite
- [ ] E2E test scenarios
- [ ] Performance test results
- [ ] Security audit report
- [ ] Test plan documentation
- [ ] Bug tracking and resolution

---

## Phase 5: Deployment

### ğŸš€ What Happens
We put the software where actual users can use it (Live / Production).

### How Experienced Engineers Approach It

| Approach | Description |
|----------|-------------|
| **Automate It** | Don't copy files manually. Use a script. |
| **Small Steps** | Release small changes often. It's safer. |
| **Have a Backup Plan** | If things break, be ready to "Undo" (Rollback) immediately. |

### Deployment Strategies (How to go live safely)

#### 1. Blue-Green Deployment (The "Safety Switch")
You have two identical environments: Blue (Live) and Green (New).
- You deploy to Green. Test it.
- If it works, you flip a switch. Now Green is Live.
- If it breaks, flip the switch back to Blue.

#### 2. Canary Deployment (The "Tester Group")
Release the new version to only 5% of users.
- If they are happy (no errors), release to everyone.
- If they complain, fix it before the other 95% see it.

#### 3. Feature Flags (The "Light Switch")
The code is live, but hidden behind a switch.
```python
if feature_enabled("new_dark_mode"):
    show_dark_mode()
else:
    show_normal_mode()
```
You can turn features on/off instantly without deploying new code.

### CI/CD Pipeline (The "Automation Robot")
Ideally, you have a robot (Jenkins, GitHub Actions) that does this:
1.  **Test**: Runs your tests automatically.
2.  **Build**: Packages your code.
3.  **Deploy**: Puts it on the server.

---

## Phase 6: Maintenance & Operations

### ğŸ”§ What Happens
The software is live. Now we must keep it running, fix bugs, and handle "incidents" (when things break).

### Monitoring: The 4 Vital Signs
Just like a doctor checks your pulse, we check the software's pulse.

1.  **Latency**: Speed. Is it slow?
2.  **Traffic**: Demand. Are too many people using it at once?
3.  **Errors**: Health. Are requests failing (500 errors)?
4.  **Saturation**: Capacity. Is the server running out of memory?

### Incident Response (What to do when it crashes)
1.  **Detect**: The alarm goes off (Slack alert/PagerDuty).
2.  **Triange**: How bad is it? (Sev 1 = Website is down. Sev 3 = Minor annoyance).
3.  **Fix**: Get the site back up first. Investigate *why* later.
4.  **Post-Mortem**: A meeting to discuss what happened so it doesn't happen again. **No blaming people!** Fix the process.

### Real-World Example: Netflix "Chaos Monkey"
Netflix wrote a program called **Chaos Monkey** that randomly turns off servers.
*Why?* To force their engineers to build systems that survive failure automatically. If the software can survive a random monkey attack, it can survive anything.

### Common Pitfalls & Issues

| Pitfall | Real Issue Faced | Solution |
|---------|------------------|----------|
| **Alert fatigue** | Too many alerts, team ignores them all | Tune alerts, prioritize actionable ones only |
| **No documentation** | Only original developer knows how it works | Documentation as part of Definition of Done |
| **Ignoring tech debt** | MySpace couldn't adapt to changes, lost to Facebook | Allocate 20% time for maintenance |
| **No monitoring** | Discovered issues from user complaints (too late) | Proactive monitoring with dashboards |
| **Blame culture** | Engineers hide mistakes, problems repeat | Blameless post-mortems focus on systems |
| **Hero culture** | One person always fixes everything | On-call rotations, knowledge sharing |

### Deliverables Checklist

- [ ] Monitoring and alerting setup
- [ ] Runbooks for common incidents
- [ ] On-call schedule and escalation paths
- [ ] Performance baselines
- [ ] Backup and recovery procedures
- [ ] Security patch management process
- [ ] SLA/SLO definitions

---

## Phase 7: Iteration & Evolution

### ğŸ“ˆ What Happens
Software is never "done." We listen to users and make it better.

### Improvement Cycle
1.  **Feedback**: Users complain or ask for things.
2.  **Metrics**: We look at the data (Are people using the new button?).
3.  **Plan**: We decide what to do next.

### Technical Debt (The "Mess" you left behind)
Sometimes you code fast to meet a deadline. You take shortcuts. This is called **Technical Debt**.
- **Interest**: If you don't fix it later, it becomes harder to add new features.
- **Pay it off**: Spend time cleaning up old code regularly.

---

## SDLC Models (Different ways to work)

### 1. Waterfall (The "Construction" way)
You do one step at a time. You can't go back.
*   **Best for**: Building bridges, medical devices where safety is key.
*   **Bad for**: Websites where ideas change often.

### 2. Agile / Scrum (The "Flexible" way)
You build a little bit, show it to the user, get feedback, and build more.
*   **Sprint**: A 2-week period where you focus on a few tasks.
*   **Standup**: A daily 15-minute meeting to say what you are doing.
*   **Best for**: Most software today (Web apps, Mobile apps).

---

## Key Takeaways

1.  **Plan before you build.** (Design phase > Coding phase).
2.  **Automate everything.** Machines don't make mistakes; humans do.
3.  **Test early.** Fixing a bug today is cheaper than fixing it next month.
4.  **Don't blame people.** If something breaks, fix the system.
5.  **Keep it simple.** Simple code is better than clever code.

---

## Resources (Where to learn more)

### ğŸ“š Essential Reading
- **"Clean Code"** (Robert C. Martin) - The handbook for writing code that is easy to understand and maintain.
- **"The Phoenix Project"** (Gene Kim) - A novel about DevOps that teaches you how *not* to run a confusing project.
- **"Designing Data-Intensive Applications"** (Martin Kleppmann) - Advanced guide for system architecture.
- **"The Pragmatic Programmer"** (David Thomas & Andrew Hunt) - Mindset and tips for professional developers.

### ğŸ”— Websites & Standards
- **[The Twelve-Factor App](https://12factor.net/)** - The gold standard for modern web app architecture.
- **[Martin Fowler's Blog](https://martinfowler.com/)** - Deep dives into patterns like Microservices and CI/CD.
- **[Google SRE Book](https://sre.google/sre-book/table-of-contents/)** - How Google runs massive systems.
- **[OWASP Top 10](https://owasp.org/)** - The standard checklist for web security.

### ğŸ›  Tools by Phase

| Phase | Recommended Tools |
|-------|-------------------|
| **requirements** | Jira, Confluence, Miro (Whiteboarding), Figma (UI) |
| **Design** | Draw.io, Mermaid.js, PlantUML, Lucidchart |
| **Implementation** | VS Code, Git, GitHub/GitLab, Docker |
| **Testing** | Jest (JS), Pytest (Python), Selenium (E2E), Postman (API) |
| **Deployment** | GitHub Actions, Jenkins, Terraform, AWS/Azure |
| **Maintenance** | Datadog, Grafana, PagerDuty, Sentry |

---
*Last Updated: January 2026*
*Author: Software Engineering Knowledge Base*
